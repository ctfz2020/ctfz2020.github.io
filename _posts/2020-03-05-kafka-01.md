---
title: Kafka重要参数说明
tags:
  - Kafka
---

最近kafka使用上遇到的坑不少,稍微总结下

<!--more-->

## 概念

kafka中有个几个重要的概念:

* topic: 消息集合,用于存储同一类数据,不同topic互不相关
* 分区数: 每个topic有个分区数的属性,topic的数据会在多个分区并行处理.  每个分区会分配到一个kafka broker上, 为了发挥集群的性能, 分区数需要为kafka broker数量的倍数.
* 分区副本: 每个分区都可以设置至少1个副本,可以防止机器宕机后分区不可以用
* 生产者: 接入数据到topic的客户端
* 消费者: 接收topic数据的客户端

### 分区的特点

每个分区只能被一个消费者订阅,但是一个消费者可以订阅多个分区,属于多对一的关系

kafka会为每个分区在磁盘创建一个目录,用于写入数据.为了更好的发挥磁盘性能,并且支持更多的消费者, 建议每个topic的分区在broker上面分配**2~4个**.但是不建议分配更多的分区,因为每个分区都会有对应相同数量的副本, 分区越多, 副本也越多, 磁盘上的目录也会越多,磁盘空间占用也越大,下面介绍的log.retention.bytes参数和分区数也有关系.

下面以每个broker分配2个分区为例

* 假设kafka集群有3台机器,那么就设置分区数为6,这样会分配到每个broker上面2个分区+2副本

* 假设kafka集群有5台机器,那么就设置分区数为10,这样会分配到每个broker上面2个分区+2副本
* 假设kafka集群有7台机器,那么就设置分区数为14,这样会分配到每个broker上面2个分区+2副本

### Kafka服务器配置

另外需要注意的是kafka服务器配置, kafka服务器配置参数 

* log.retention.bytes 针对每个分区设置,分区越多磁盘空间占用越多,这个参数在设置前要根据磁盘大小计算得到,同时要保留20%的空间用于存放日志和其它数据,计算公式为:**`broker数量*磁盘空间*0.8/topic个数/分区数/副本数`**
* message.max.bytes 最大消息大小
* fetch.message.max.bytes 同步副本时拉取数据大小,最好与`message.max.bytes`参数一致, 太大会影响kafka的副本同步功能,当内存设置过小时会导致OOM异常.

### Topic

创建topic时,分区数建议为broker数量的两倍,如果没有特殊要求,副本设置为2.

### Kafka生产者参数

根据性能测试,当每条数据在500B时,最优参数为`buffer.memory=67108864,batch.size=81920,linger.ms=20,compression.type=lz4`

* batch.size

  通过Productor.send方法添加的数据并不会立即发送, 而且填充到batch中,等batch满了才会触发数据压缩并发送给服务器,建议设置80k,即81920.

* linger.ms

  当batch中的数据没有达到容量时,等待时间,等待时间越久,batch中的数据越容易达到容量, 但是数据延迟变大,建议设置20.

* buffer.memory

  生产者内部使用的内存大小,用于缓存发送的数据.可以随着发送的topic对应的分区数变多而增大,默认32M.

* compression.type

  数据压缩算法, 可以将batch的数据进行压缩,没有特殊要求时,建议使用lz4算法

### Kafka消费者参数

* max.partition.fetch.bytes

  参数没有设置, 在kakfa0.10.1.0版本之前该参数小于服务器端message.max.bytes时,就会导致消费失败,并且消费者会一直重试,导致消费停止,程序出现问题. 建议该参数与message.max.bytes保持一直,设置为50m.

* max.poll.records

  每次拉取最大数据条数, 默认500, 消费者通过poll操作与服务器保持心跳. 当数据很复杂时,处理每条数据都会消耗一定的时间, 很可能500条数据处理完成后,再调用poll操作客户端已经和服务器断开连接,会触发客户端重连,然后产生数据重复消费的问题,该值根据数据处理复杂度设置.

## 最大数据传输量

压缩与解压缩都是在客户端执行的, 生产者在发送数据前压缩数据, 消费者在收到数据后解压缩数据, kafka服务器没有参与. 但是影响kafka服务器性能的参数有网络io和磁盘io,数据压缩比例越大,kafka服务器收到的数据越少,总体消息数量也越大

### 压缩算法

每个kafka生产者只有一个线程在压缩数据,所以单个生产者性能有限,不同的压缩算法消费的cpu也不一样,总体趋势是压缩比例越大,cpu越高

以kafka2.5.0版本为例, 单个线程提供的压缩算法压缩比如下,cpu频率为2.6GHZ

| 压缩方式 | 压缩比 | 处理数据MB/s | 压缩后数据MB/s |
| -------- | ------ | ------------ | -------------- |
| none     | 1:1    | 87.1         | 87.1           |
| gzip     | 6.1:1  | 21.5         | 3.5            |
| snappy   | 2.7:1  | 104.9        | 39.5           |
| lz4      | 2.7:1  | 107.6        | 39.9           |
| zstd     | 6.0:1  | 58.2         | 9.6            |

其中lz4处理数据最快,压缩比较低,当网络io不是瓶颈时,可以使用该算法.

zstd压缩比较高,且处理速度较快,当网络io处于瓶颈时, 可以消费较多cpu资源提高最大数据处理速度.

### Broker网络模型

当topic分区为broker数量的2倍,副本为2时,整个kafka的数据流向如下图

![broker网络](/assets/broker_network.png)

每个broker流量分为4个部分

* producer发送给broker,为总流量的1/3,对于broker节点, 方向为**&darr;**

* 副本同步,当前节点上面的主副本向从副本同步, 为总流量的1/3,方向为**&darr;**

* 副本同步,当前节点上面的从副本拉取主副本,为总流量的1/3,方向为**&uarr;**

* consumer订阅,为总流量的1/3, 对于broker节点, 方向为**&uarr;**

也就是对于3个broker的集群,每个broker输入流量和输出流量都为`2/3`倍的总流量.

当broker网卡为千兆时,该集群最大输入流量为**`1024Mbs / 8 * 2 / 3 = 192MBs`**



再根据生产者设置不同的压缩算法时的输出流量,可以得到以下数据

### 千兆网卡

<!--markdown不直接支持合并单元格, 参考https://www.zhihu.com/question/50267650/answer/156817258 -->

<table>
	<tr>
	    <th>broker数量</th>
        <th>单个broker输入占总流量比例</th>
	    <th>集群输入流量(MB/s)</th>
	    <th>生产者压缩算法</th>
		<th>生产者数量</th>
		<th>原始数据最大数据量(MB/s)</th>
	</tr>
	<tr>
	    <td rowspan="3">3</td>
        <td rowspan="3">2/3</td>
        <td rowspan="3">192</td>
        <td>lz4</td>
	    <td>5</td>
        <td>517</td>
    </tr>
	<tr>
        <td>zstd</td>
        <td>20</td>
        <td>1164</td>
    </tr>
    <tr>
        <td>gzip</td>
        <td>54</td>
        <td>1179</td>
    </tr>
    <tr>
        <td rowspan="3">5</td>
        <td rowspan="3">2/5</td>
        <td rowspan="3">320</td>
        <td>lz4</td>
        <td>8</td>
        <td>863</td>
    </tr>
    <tr>
        <td>zstd</td>
        <td>34</td>
        <td>1940</td>
    </tr>
    <tr>
        <td>gzip</td>
        <td>92</td>
        <td>1965</td>
    </tr>
    <tr>
        <td rowspan="3">7</td>
        <td rowspan="3">2/7</td>
        <td rowspan="3">448</td>
        <td>lz4</td>
        <td>12</td>
        <td>1208</td>
    </tr>
    <tr>
        <td>zstd</td>
        <td>47</td>
        <td>2716</td>
    </tr>
    <tr>
        <td>gzip</td>
        <td>128</td>
        <td>2752</td>
    </tr>
</table>